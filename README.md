# ğŸœ Smart Noodle Vending Machine â€“ Agentic AI Backend

## ğŸ“Œ Project Overview

This project implements an Agentic AI backend for a Smart IoT-based Noodle Vending Machine.
The AI agent interacts with users through a mobile or web interface, understands their mood, situation, or intent, and intelligently recommends one of four available noodle flavors.

The system is designed as part of the MyUrbanECD IoT Project, where:

The IoT hardware vending machine is developed separately

This repository focuses on the AI-powered backend and API layer

## ğŸ¯ Key Features

ğŸ¤– Agentic AI using Hugging Face LLM (Phi-2 / TinyLlama)

ğŸ’¬ Natural language chat-based interaction

ğŸ§  Context-aware noodle recommendation

âš¡ GPU-accelerated inference (RTX 3050 â€“ 6GB VRAM)

ğŸŒ REST API using FastAPI

ğŸ§ª Built-in Swagger UI for testing

ğŸ”„ Lazy AI model loading (stable & efficient)

ğŸœ Available Noodle Options

## The AI agent recommends only one of the following:

Hot Spicy Ramen â€“ Cold weather / strong hunger

Chicken Noodles â€“ Starving or high energy need

Cheese Noodles â€“ Exhausted / comfort food

Veg Clear Soup â€“ Light meal / low appetite

## ğŸ§  System Architecture (High Level)
User (Mobile / Web App)
        â†“
   FastAPI Backend
        â†“
  Agentic AI (LLM)
        â†“
Noodle Recommendation
        â†“
 IoT Vending Machine (Future Integration)

## ğŸ› ï¸ Technology Stack
Backend

Python 3.10

FastAPI

Uvicorn

AI & ML

PyTorch (CUDA-enabled)

Hugging Face Transformers

Accelerate

SentencePiece

Hardware

NVIDIA GPU (Tested on RTX 3050 â€“ 6GB VRAM)

## ğŸ“¦ Project Structure
``IOT_Project/
â”‚
â”œâ”€â”€ main.py            # FastAPI application
â”œâ”€â”€ ai_model.py        # AI model loading & inference
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ README.md          # Project documentation ``

## âš™ï¸ Installation & Setup
### 1ï¸âƒ£ Clone the Repository
``git clone <your-repo-url>
cd IOT_Project``

### 2ï¸âƒ£ Create Virtual Environment (Recommended)
python -m venv venv
venv\Scripts\activate

### 3ï¸âƒ£ Install CUDA-Enabled PyTorch (IMPORTANT)

âš ï¸ PyTorch with CUDA must be installed separately.

``pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118``

### 4ï¸âƒ£ Install Remaining Dependencies
``pip install -r requirements.txt``

### 5ï¸âƒ£ Verify GPU Availability
`` python
import torch
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0)) ``


Expected output:

True
NVIDIA GeForce RTX 3050(your)

## ğŸš€ Running the Application
Start FastAPI Server
uvicorn main:app


Server will run at:

``http://127.0.0.1:8000``

## ğŸ§ª API Testing (Swagger UI)

### Open your browser:

``http://127.0.0.1:8000/docs``

### Test Endpoint: /chat

Request Body
``
{
  "user_message": "I'm exhausted and it's cold today"
}
``

Sample Response
``
{
  "reply": "You seem tired and cold. A hot spicy ramen would be perfect for you ğŸœ"
}
``
##ğŸ¤– AI Design Approach

Uses a lightweight LLM suitable for limited VRAM

Implements lazy model loading to prevent startup crashes

Combines agent logic + natural language understanding

Designed for future IoT availability checks

## ğŸ”® Future Enhancements

ğŸ”— Real-time IoT inventory & availability check

ğŸ§  Conversation memory

ğŸ“± Flutter mobile chat interface

ğŸŒ Multi-language support

ğŸ³ Docker + GPU deployment

ğŸ“„ Academic Note

## This project demonstrates:

Practical use of Agentic AI

GPU-accelerated local LLM deployment

Clean API design with FastAPI

Industry-standard dependency management

## ğŸ‘¨â€ğŸ’» Author

Raveesha
Software Engineering Student
MyUrbanECD IoT Project
